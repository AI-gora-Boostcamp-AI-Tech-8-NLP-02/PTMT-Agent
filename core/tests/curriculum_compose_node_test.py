# uv run python core/tests/curriculum_compose_node_test.py
import os
import sys
import asyncio
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from core.graphs.nodes import curriculum_compose_node
from core.graphs.state_definition import CreateCurriculumOverallState

from langgraph.graph import StateGraph, START, END

async def main():
    load_dotenv()
    
    print("ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘: Curriculum Compose Node (LangGraph Execution)")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    data_dir = project_root / "tests" / "dummy_data"
    user_path = data_dir / "dummy_user_information.json"
    curriculum_path = data_dir / "dummy_initial_curriculum.json"
    
    try:
        with open(user_path, "r") as f:
            user_info = json.load(f)
        with open(curriculum_path, "r") as f:
            curriculum_data = json.load(f)

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 1. Test Curriculum Compose Node
    print("\n[1] Testing curriculum_compose_node...")
    
    state_v1: CreateCurriculumOverallState = {
        "curriculum": curriculum_data,
        "user_info": user_info,
        "paper_name": "Test",
        "paper_summary": "",
        "initial_keywords": [],
        "paper_content": {},
        "final_curriculum": {},
        "keyword_subgraph": {},
        "is_keyword_sufficient": True,
        "is_resource_sufficient": True,
        "current_iteration_count": 0,
        "keyword_expand_reason": "",
        "tasks": [],
        "needs_description_ids": [],
        "insufficient_resource_ids": [],
        "missing_concepts": [],
        "keyword_reasoning": "",
        "resource_reasoning": ""
    }

    try:
        # LangGraph êµ¬ì„±
        workflow = StateGraph(CreateCurriculumOverallState)
        workflow.add_node("curriculum_compose", curriculum_compose_node)
        workflow.add_edge(START, "curriculum_compose")
        workflow.add_edge("curriculum_compose", END)
        
        app = workflow.compile()
        
        # LangGraph ì‹¤í–‰
        result_state = await app.ainvoke(state_v1)
        new_curr = result_state.get("curriculum", {})
        
        print("âœ… curriculum_compose_node ì™„ë£Œ")
        
        # ìƒì„¸ ë³€ê²½ ë‚´ì—­ ë¶„ì„
        nodes_before = curriculum_data["nodes"]
        total_res_before = sum(len(n.get("resources", [])) for n in nodes_before)
        
        # ì›ë³¸ ë¡œë“œ ê³„ì‚°
        total_load_before = 0.0
        for n in nodes_before:
            for r in n.get("resources", []):
                try:
                    load = float(r.get("study_load", 0))
                except:
                    load = 0.0
                total_load_before += load

        # ê²°ê³¼ ë¡œë“œ ë° ìƒíƒœ ê³„ì‚°
        new_nodes = new_curr.get("nodes", [])
        total_res_after = 0
        emphasize_load = 0.0
        preserve_load = 0.0
        
        print("\n[ìƒì„¸ ë³€ê²½ ë‚´ì—­ (Resources)]")
        for n in new_nodes:
            # ë³€ê²½ëœ ë…¸ë“œì˜ ë¦¬ì†ŒìŠ¤ í™•ì¸
            # (ê¸°ì¡´ ë…¸ë“œì™€ ë§¤ì¹­í•´ì„œ ë³€í™”ë¥¼ ë³¼ ìˆ˜ë„ ìˆì§€ë§Œ, ê²°ê³¼ ìƒíƒœ ìœ„ì£¼ë¡œ ì¶œë ¥)
            has_print_node = False
            
            for r in n.get("resources", []):
                total_res_after += 1
                try:
                    load = float(r.get("study_load", 0) or 0)
                except:
                    load = 0.0
                
                is_nec = r.get("is_necessary")
                
                if is_nec:
                    status = "ğŸ”´ EMPHASIZE"
                    emphasize_load += load
                else:
                    status = "âšª PRESERVE"
                    preserve_load += load
                
                if not has_print_node:
                    print(f"\n[{n['keyword']}]")
                    has_print_node = True
                    
                print(f"  {status} : {r['resource_name']} ({load}h)")

        total_load_after = emphasize_load + preserve_load
        
        print("\n" + "=" * 40)
        print(f"Original Resources: {total_res_before} (Load: {total_load_before:.1f}h)")
        print(f"Final Resources   : {total_res_after} (Deleted: {total_res_before - total_res_after})")
        print("-" * 40)
        print(f"ğŸ”´ EMPHASIZE Load : {emphasize_load:.1f}h")
        print(f"âšª PRESERVE Load  : {preserve_load:.1f}h")
        print(f"Total Load        : {total_load_after:.1f}h")
        print("=" * 40)
        
    except Exception as e:
        print(f"âŒ curriculum_compose_node ì‹¤íŒ¨: {e}")

    print("\n" + "=" * 60)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
