# uv run python core/tests/paper_concept_alignment_node_test.py
import os
import sys
import asyncio
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from core.graphs.nodes import paper_concept_alignment_node
from core.graphs.state_definition import CreateCurriculumOverallState

from langgraph.graph import StateGraph, START, END

async def main():
    load_dotenv()
    
    print("ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘: Paper Concept Alignment Node (LangGraph Execution)")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    data_dir = project_root / "tests" / "dummy_data"
    curriculum_path = data_dir / "dummy_initial_curriculum.json"
    paper_path = data_dir / "dummy_parsing_paper.json"
    
    try:
        with open(curriculum_path, "r") as f:
            curriculum_data = json.load(f)
            
            # paper_concept_alignment í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¼ë¶€ description ë¹„ìš°ê¸°
            for node in curriculum_data["nodes"][:3]:
                 node["description"] = ""
        
        with open(paper_path, "r") as f:
            paper_info = json.load(f)

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. Test Paper Concept Alignment Node
    print("\n[1] Testing paper_concept_alignment_node...")
    
    state_v2: CreateCurriculumOverallState = {
        "curriculum": curriculum_data,
        "paper_content": paper_info,
        "user_info": {},
        "paper_name": "Test",
        "paper_summary": "",
        "initial_keywords": [],
        "final_curriculum": {},
        "keyword_subgraph": {},
        "is_keyword_sufficient": True,
        "is_resource_sufficient": True,
        "current_iteration_count": 0,
        "keyword_expand_reason": "",
        "tasks": [],
        "needs_description_ids": [],
        "insufficient_resource_ids": [],
        "missing_concepts": [],
        "keyword_reasoning": "",
        "resource_reasoning": ""
    }
    
    # Target Nodes í™•ì¸ (description ë¹„ìš´ ë…¸ë“œë“¤)
    target_node_ids = [n["keyword_id"] for n in curriculum_data["nodes"][:3]]
    print(f"ğŸ¯ Target Nodes (Description cleared): {target_node_ids}")
    
    try:
        # LangGraph êµ¬ì„±
        workflow = StateGraph(CreateCurriculumOverallState)
        workflow.add_node("paper_concept_alignment", paper_concept_alignment_node)
        workflow.add_edge(START, "paper_concept_alignment")
        workflow.add_edge("paper_concept_alignment", END)
        
        app = workflow.compile()
        
        # LangGraph ì‹¤í–‰
        result_state = await app.ainvoke(state_v2)
        new_curr_v2 = result_state.get("curriculum", {})
        
        print("âœ… paper_concept_alignment_node ì™„ë£Œ")
        
        # Description í™•ì¸
        filled_desc = 0
        print("\n[Description ì±„ìš°ê¸° ê²°ê³¼]")
        
        for node in new_curr_v2.get("nodes", []):
            kid = node.get("keyword_id")
            desc = node.get("description", "")
            
            # ì „ì²´ í†µê³„
            if desc:
                filled_desc += 1
            
            # íƒ€ê²Ÿ ë…¸ë“œ í™•ì¸
            if kid in target_node_ids:
                status = "âœ… FILLED" if desc else "âŒ EMPTY"
                print(f"  - [{kid}] {node['keyword']}: {status}")
                if desc:
                    print(f"    -> {desc[:60]}...") # ë‚´ìš© ì¼ë¶€ ì¶œë ¥

        print(f"\n  - Total Nodes with Description: {filled_desc}/{len(new_curr_v2.get('nodes', []))}")
        
    except Exception as e:
        print(f"âŒ paper_concept_alignment_node ì‹¤íŒ¨: {e}")

    print("\n" + "=" * 60)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
