import asyncio
import json
import os
from dotenv import load_dotenv
from typing import Literal, List, Dict, Any

from langgraph.graph import StateGraph, START, END


from core.graphs.subgraph_to_curriculum import transform_subgraph_to_final_curriculum
from core.graphs.parallel.nodes_parallel import (
    curriculum_orchestrator_node, 
    resource_discovery_agent_node,
    curriculum_compose_node,
    concept_expansion_node,
    paper_concept_alignment_node
)
from core.graphs.parallel.state_parallel import CreateCurriculumOverallState

def create_initial_state(
    subgraph_data: Dict[str, Any],
    user_info_data: Dict[str, Any],
    paper_raw_data: Dict[str, Any]
) -> CreateCurriculumOverallState:
    """
    ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ Transformì„ ìˆ˜í–‰
    LangGraph ì‹¤í–‰ì„ ìœ„í•œ Initial Stateë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜
    """
    
    
    meta_data_input = {
        "paper_id": paper_raw_data.get("paper_id", "Unknown ID"), 
        "title" : paper_raw_data.get("title", "Unknown Title"),
        "summarize": paper_raw_data.get("abstract", "") # Use abstract as summary for now
    }

    # Subgraph -> Curriculum ë³€í™˜ (Transform)
    curriculum_data = transform_subgraph_to_final_curriculum(subgraph_data, meta_data_input)

    # Initial State 
    initial_state = {
        "paper_name": paper_raw_data.get("title", "Unknown"),
        "paper_summary": paper_raw_data.get("abstract", ""),
        "initial_keywords": [n.get("keyword") for n in curriculum_data.get("nodes", [])],
        "paper_content": paper_raw_data,
        "user_info": user_info_data,
        "curriculum": curriculum_data,
        "tasks": [],
        "current_iteration_count": 0, # ì‹œì‘ ì¹´ìš´íŠ¸ 0
        "is_keyword_sufficient": False,
        "is_resource_sufficient": False,
        "needs_description_ids": [],
        "insufficient_resource_ids": [],
        "missing_concepts": [],
        "keyword_reasoning": "Init",
        "resource_reasoning": "Init",
        "keyword_expand_reason": ""
    }

    return initial_state

# Router: ë³‘ë ¬ ì‹¤í–‰
def orchestrator_router(state: CreateCurriculumOverallState) -> List[str]:
    tasks = state.get("tasks", [])
    current_count = state.get("current_iteration_count", 0)
    MAX_ITERATIONS = 6

    # ì¢…ë£Œ ì¡°ê±´: íƒœìŠ¤í¬ê°€ ì—†ê±°ë‚˜ ë°˜ë³µ íšŸìˆ˜ ì´ˆê³¼ ì‹œ
    if not tasks: 
        print("ğŸ [Router] ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ. ìµœì¢… ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        return ["curriculum_compose"]
    
    if current_count >= MAX_ITERATIONS:
        print("âš ï¸ [Router] ë°˜ë³µ íšŸìˆ˜ ì´ˆê³¼. ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return ["curriculum_compose"]

    # ë³‘ë ¬ ì‹¤í–‰í•  ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ 
    next_nodes = []
    
    # tasks ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” í‚¤ì›Œë“œë¥¼ ë³´ê³  ì‹¤í–‰í•  ë…¸ë“œë¥¼ ê²°ì •
    if "generate_description" in tasks: 
        next_nodes.append("paper_concept_alignment")
    if "resource_search" in tasks: 
        next_nodes.append("resource_discovery")
    if "keyword_expansion" in tasks: 
        next_nodes.append("concept_expansion")

    # tasksì—ëŠ” ìˆëŠ”ë° ë§¤í•‘ëœ ë…¸ë“œê°€ ì—†ëŠ” ê²½ìš°
    if not next_nodes:
        return ["curriculum_compose"]
        
    print(f"ğŸ”€ [Parallel] ë‹¤ìŒ ì—ì´ì „íŠ¸ë“¤ ë™ì‹œ ì‹¤í–‰: {next_nodes} (Loop: {current_count})")
    
    return next_nodes


# Join Node, ê²°ê³¼ ë³‘í•© í›„ì²˜ë¦¬
async def join_parallel_results_node(state: CreateCurriculumOverallState):
    """
    ë³‘ë ¬ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì´ ë¦¬ë“€ì„œë¥¼ í†µí•´ ë°ì´í„°ë¥¼ í•©ì¹˜ê³  task ì •ë¦¬
    """
    print(" [Join] ë³‘ë ¬ ì‘ì—… ì™„ë£Œ. Task ëª©ë¡ ì •ë¦¬ ì¤‘...")
    remaining_tasks = [ ]
    
    return {
        "tasks": remaining_tasks
    }


def run_langgraph_workflow():
    # StateGraph êµ¬ì„±
    workflow = StateGraph(CreateCurriculumOverallState)

    # ë…¸ë“œ ë“±ë¡
    workflow.add_node("orchestrator", curriculum_orchestrator_node)
    workflow.add_node("resource_discovery", resource_discovery_agent_node)
    workflow.add_node("paper_concept_alignment", paper_concept_alignment_node)
    workflow.add_node("concept_expansion", concept_expansion_node)
    workflow.add_node("curriculum_compose", curriculum_compose_node)
    
    # join ë…¸ë“œ ë“±ë¡
    workflow.add_node("join_results", join_parallel_results_node)

    # ì—£ì§€ ì—°ê²°
    workflow.add_edge(START, "orchestrator")
    
    # ë³‘ë ¬ ë…¸ë“œë“¤
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ map ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ì™€ ì¼ì¹˜í•˜ëŠ” ë…¸ë“œë“¤ì´ ë™ì‹œ ì‹¤í–‰ë¨
    workflow.add_conditional_edges(
        "orchestrator",
        orchestrator_router,
        {
            "resource_discovery": "resource_discovery",
            "paper_concept_alignment": "paper_concept_alignment",
            "concept_expansion": "concept_expansion",
            "curriculum_compose": "curriculum_compose"
        }
    )

    
    # ì¼ì´ ëë‚˜ë©´ ë¬´ì¡°ê±´ Join ë…¸ë“œë¡œ ëª¨ì„
    workflow.add_edge("resource_discovery", "join_results")
    workflow.add_edge("paper_concept_alignment", "join_results")
    workflow.add_edge("concept_expansion", "join_results")
    workflow.add_edge("join_results", "orchestrator")

    # ì¢…ë£Œ ì²˜ë¦¬
    workflow.add_edge("curriculum_compose", END)

    # ì»´íŒŒì¼
    return workflow.compile()